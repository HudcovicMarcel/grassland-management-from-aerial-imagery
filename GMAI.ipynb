{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "rGz40AzmOsgu",
        "YNuyC0HjPhsM",
        "fv4uzZfCp3Nv",
        "24FGzD1t7hTu",
        "3Xl0-l7wBaOC"
      ],
      "mount_file_id": "1jJHC4HpZEuSOq6CaCesBxK_DqZXVWK0z",
      "authorship_tag": "ABX9TyOKwC1Ko1Vlur8Iy8fZmVwt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HudcovicMarcel/grassland-management-from-aerial-imagery/blob/main/GMAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grassland Management from Aerial Imagery (GMAI)\n",
        "\n",
        "This notebook serves as supplementary material for the [GMAI dataset and repository](https://github.com/HudcovicMarcel/grassland-management-from-aerial-imagery).  \n",
        "It provides a **step-by-step demonstration** of the methodology used in the referenced study.  \n",
        "\n",
        "The notebook can be run using the **Demo Data and Model** available from the Zenodo repository, which can be downloaded in the first step.\n",
        "\n",
        "The demo data includes seven images and corresponding label files for each class in the dataset.  \n",
        "**Note:** We do **not recommend training** the model with this small demo dataset.  \n",
        "For actual training or reproducing results, please use the full `dataset.zip` from the repository.\n"
      ],
      "metadata": {
        "id": "rGz40AzmOsgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0.1. Demo data download**\n",
        "\n",
        "Downloads demo data from Zenodo repository."
      ],
      "metadata": {
        "id": "z0o7TTWW-VI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "demo_url = \"https://zenodo.org/records/17350381/files/demo_data.zip?download=1\"\n",
        "model_url = \"https://zenodo.org/records/17350381/files/YOLO11x_GMAI.pt?download=1\"\n",
        "\n",
        "output_dir = \"GMAI\"\n",
        "demo_zip = \"demo_data.zip\"\n",
        "model_file = os.path.join(output_dir, \"YOLO11x_GMAI.pt\")\n",
        "\n",
        "r = requests.get(demo_url, stream=True)\n",
        "with open(demo_zip, \"wb\") as f:\n",
        "    for chunk in r.iter_content(chunk_size=8192):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(demo_zip, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(output_dir)\n",
        "\n",
        "macosx_path = os.path.join(output_dir, \"__MACOSX\")\n",
        "if os.path.exists(macosx_path):\n",
        "    shutil.rmtree(macosx_path)\n",
        "\n",
        "r = requests.get(model_url, stream=True)\n",
        "with open(model_file, \"wb\") as f:\n",
        "    for chunk in r.iter_content(chunk_size=8192):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "\n",
        "print('Data downloaded')"
      ],
      "metadata": {
        "id": "t71-Lx0RvVcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0.2. Install neccessary packages**"
      ],
      "metadata": {
        "id": "-qzC1htI-9xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "7CuQHLF-OWgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Dataset creation**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YNuyC0HjPhsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1. Importing prerequsisites**"
      ],
      "metadata": {
        "id": "_EQiREbXKeM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import shutil\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import yaml\n"
      ],
      "metadata": {
        "id": "0UqxCIqnK09T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2. Image tiling**"
      ],
      "metadata": {
        "id": "q4RNJ0OrS5C3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbsmpZMzKcxE"
      },
      "outputs": [],
      "source": [
        "img_path = '/content/GMAI/SAMPLE_ORTO' # Folder path with images\n",
        "out_path = '/content/GMAI/SAMPLE_TILES' # Output folder for tiles\n",
        "\n",
        "os.makedirs(out_path,exist_ok=True)\n",
        "\n",
        "image_files = []\n",
        "\n",
        "for dirpath, _, filenames in os.walk(img_path):\n",
        "    for file in filenames:\n",
        "        if file.lower().endswith(('.tif', '.tiff')): # Change according to your image file extension\n",
        "            full_path = os.path.join(dirpath, file)\n",
        "            image_files.append(full_path)\n",
        "for image in image_files:\n",
        "    with rasterio.open(image,\"r+\") as src:\n",
        "        image_width = src.width\n",
        "        image_height = src.height\n",
        "        tiling_size = 1280  # Final size of image\n",
        "        overlap = 0.1   # Overlap between images\n",
        "        stride_x, stride_y = int(tiling_size * (1 - overlap)), int(tiling_size * (1 - overlap))\n",
        "\n",
        "        tile_id=0\n",
        "\n",
        "        for top in range(0, image_height, stride_y):\n",
        "            for left in range(0, image_width, stride_x):\n",
        "                if left + tiling_size > image_width:\n",
        "                    left = image_width - tiling_size\n",
        "                if top + tiling_size > image_height:\n",
        "                    top = image_height - tiling_size\n",
        "                window = Window(left, top, tiling_size, tiling_size)\n",
        "                bounds = rasterio.windows.bounds(window, transform=src.transform)\n",
        "                minX, minY, maxX, maxY = bounds\n",
        "                tile_path = os.path.join(out_path, f\"{os.path.basename(os.path.splitext(image)[0])}_{tile_id}.tif\") #Tile name will contain name of image plus tile ID\n",
        "                tile_id+=1\n",
        "                tile_data = src.read(indexes=[1, 2, 3],window=window)\n",
        "                with rasterio.open(\n",
        "                                tile_path,\n",
        "                                \"w\",\n",
        "                                driver=\"GTiff\",\n",
        "                                height=tile_data.shape[1],\n",
        "                                width=tile_data.shape[2],\n",
        "                                count=3,\n",
        "                                dtype=tile_data.dtype,\n",
        "                                crs=src.crs,\n",
        "                                transform=src.window_transform(window),\n",
        "                            ) as dst:\n",
        "                                dst.write(tile_data)\n",
        "\n",
        "print(\"Created\",(len(os.listdir(out_path))),'tiles from',(len(image_files)),'images')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3. Data labeling**\n",
        "\n",
        "All object annotations were created using the Label Studio graphical interface.  \n",
        "We recommend running Label Studio on your local computer to label or review data, as it provides a user-friendly GUI and full control over the labeling process.\n",
        "Further information on: https://labelstud.io/"
      ],
      "metadata": {
        "id": "LUKylvAaRrxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4. Data augmentation**"
      ],
      "metadata": {
        "id": "ydpwEf2DTDUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_images = '/content/GMAI/SAMPLE_DATASET/images'\n",
        "input_labels = '/content/GMAI/SAMPLE_DATASET/labels'\n",
        "\n",
        "output_images = '/content/GMAI/SAMPLE_DATASET/augmented/images'\n",
        "output_labels = '/content/GMAI/SAMPLE_DATASET/augmented/labels'\n",
        "\n",
        "os.makedirs(output_images, exist_ok=True)\n",
        "os.makedirs(output_labels, exist_ok=True)\n",
        "\n",
        "def read_yolo_labels(label_file):\n",
        "    with open(label_file, 'r') as f:\n",
        "        labels = [list(map(float, line.strip().split())) for line in f.readlines()]\n",
        "    return labels\n",
        "\n",
        "def write_yolo_labels(label_file, labels):\n",
        "    with open(label_file, 'w') as f:\n",
        "        for label in labels:\n",
        "            f.write(\" \".join(map(str, label)) + \"\\n\")\n",
        "\n",
        "# Flip horizontally\n",
        "def flip_hor(image_path, labels):\n",
        "    image = cv2.imread(image_path)\n",
        "    flipped_image = cv2.flip(image, 1)\n",
        "    flipped_labels = []\n",
        "    for label in labels:\n",
        "        class_id, x, y, w, h = label\n",
        "        flipped_labels.append([int(class_id), 1 - x, y, w, h])\n",
        "    return flipped_image, flipped_labels\n",
        "\n",
        "# Flip vertically\n",
        "def flip_ver(image_path, labels):\n",
        "    image = cv2.imread(image_path)\n",
        "    flipped_image = cv2.flip(image, 0)\n",
        "    flipped_labels = []\n",
        "    for label in labels:\n",
        "        class_id, x, y, w, h = label\n",
        "        flipped_labels.append([int(class_id), x, 1 - y, w, h])\n",
        "    return flipped_image, flipped_labels\n",
        "\n",
        "# Rotate 90° clockwise\n",
        "def rotate_90(image_path, labels):\n",
        "    image = cv2.imread(image_path)\n",
        "    rotated_image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
        "    rotated_labels = []\n",
        "    for label in labels:\n",
        "        class_id, x, y, w, h = label\n",
        "        rotated_labels.append([int(class_id), 1 - y, x, h, w])\n",
        "    return rotated_image, rotated_labels\n",
        "\n",
        "# Rotate 90° counterclockwise\n",
        "def rotate_90_ccw(image_path, labels):\n",
        "    image = cv2.imread(image_path)\n",
        "    rotated_image = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
        "    rotated_labels = []\n",
        "    for label in labels:\n",
        "        class_id, x, y, w, h = label\n",
        "        rotated_labels.append([int(class_id), y, 1 - x, h, w])\n",
        "    return rotated_image, rotated_labels\n",
        "\n",
        "# Save augmented image and labels\n",
        "def save_augmented(image, labels, base_name, suffix):\n",
        "    output_image_path = os.path.join(output_images, f\"{base_name}_{suffix}.tif\")\n",
        "    output_label_path = os.path.join(output_labels, f\"{base_name}_{suffix}.txt\")\n",
        "    cv2.imwrite(output_image_path, image)\n",
        "    write_yolo_labels(output_label_path, labels)\n",
        "\n",
        "# Load original labels\n",
        "class_counts = Counter()\n",
        "for label_file in os.listdir(input_labels):\n",
        "    if label_file.endswith(\".txt\"):\n",
        "        with open(os.path.join(input_labels, label_file), \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                class_id = int(line.split()[0])\n",
        "                class_counts[class_id] += 1\n",
        "\n",
        "\n",
        "biggest_class_count = max(class_counts.values())\n",
        "threshold_50 = biggest_class_count * 0.5\n",
        "threshold_25 = biggest_class_count * 0.25\n",
        "\n",
        "# Divides classes based on size\n",
        "more_than_50 = [cls for cls, count in class_counts.items() if count > threshold_50]\n",
        "between_25_and_50 = [cls for cls, count in class_counts.items() if threshold_25 < count <= threshold_50]\n",
        "less_than_25 = [cls for cls, count in class_counts.items() if count <= threshold_25]\n",
        "zero = [cls for cls, count in class_counts.items() if count == 0]\n",
        "\n",
        "# Loop through label files\n",
        "for label_file in os.listdir(input_labels):\n",
        "    if not label_file.endswith(\".txt\"):\n",
        "        continue\n",
        "\n",
        "    label_path = os.path.join(input_labels, label_file)\n",
        "    labels = read_yolo_labels(label_path)\n",
        "    base_name = os.path.splitext(label_file)[0]\n",
        "\n",
        "    # Copy original image and labels\n",
        "    image_path = os.path.join(input_images, f\"{base_name}.tif\")\n",
        "    shutil.copy(image_path, os.path.join(output_images, f\"{base_name}.tif\"))\n",
        "    shutil.copy(label_path, os.path.join(output_labels, f\"{base_name}.txt\"))\n",
        "\n",
        "    classes_in_image = [int(l[0]) for l in labels]\n",
        "\n",
        "    # Apply augmentations based on class counts\n",
        "    if any(cls in classes_in_image for cls in more_than_50 + zero):\n",
        "        img, lbls = flip_hor(image_path, labels)\n",
        "        save_augmented(img, lbls, base_name, \"flipped\")\n",
        "\n",
        "    if any(cls in classes_in_image for cls in between_25_and_50):\n",
        "        img, lbls = flip_hor(image_path, labels)\n",
        "        save_augmented(img, lbls, base_name, \"flipped_hor\")\n",
        "        img, lbls = flip_ver(image_path, labels)\n",
        "        save_augmented(img, lbls, base_name, \"flipped_ver\")\n",
        "        img, lbls = flip_hor(image_path, labels)\n",
        "        lbls = [[l[0], 1 - l[1], l[2], l[3], l[4]] for l in lbls]\n",
        "        save_augmented(img, lbls, base_name, \"flipped_hor_ver\")\n",
        "\n",
        "    if any(cls in classes_in_image for cls in less_than_25):\n",
        "        for func, suffix in [(flip_hor, \"flipped_hor\"), (flip_ver, \"flipped_ver\"),\n",
        "                             (rotate_90, \"rot_90\"), (rotate_90_ccw, \"rot_90_ccw\")]:\n",
        "            img, lbls = func(image_path, labels)\n",
        "            save_augmented(img, lbls, base_name, suffix)\n",
        "\n",
        "print(\"Created\", len(os.listdir(output_images)), \"augmented images from\", len(os.listdir(input_images)), \"original images.\")"
      ],
      "metadata": {
        "id": "QxuopMeBRbcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.5. Split dataset and create YAML file for training**"
      ],
      "metadata": {
        "id": "KeJJuTklokOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_folder = r\"/content/GMAI/SAMPLE_DATASET/augmented/images\"\n",
        "labels_folder = r\"/content/GMAI/SAMPLE_DATASET/augmented/labels\"\n",
        "\n",
        "output_folder = r\"/content/GMAI/SAMPLE_DATASET/final_dataset\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Define split ratios\n",
        "split_ratios = {\n",
        "    \"train\": 0.6,\n",
        "    \"val\": 0.2,\n",
        "    \"test\": 0.2\n",
        "}\n",
        "\n",
        "# Organize files by class\n",
        "class_samples = defaultdict(int)\n",
        "class_files = defaultdict(list)\n",
        "for label_file in os.listdir(labels_folder):\n",
        "    if label_file.endswith(\".txt\"):\n",
        "        with open(os.path.join(labels_folder, label_file), \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                class_id = int(line.split()[0])\n",
        "                class_samples[class_id] += 1\n",
        "            if lines:\n",
        "                class_files[class_id].append(label_file)\n",
        "\n",
        "# Create output directories\n",
        "for split in split_ratios.keys():\n",
        "    os.makedirs(os.path.join(output_folder, split, \"labels\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(output_folder, split, \"images\"), exist_ok=True)\n",
        "\n",
        "# Dictionary to store class distributions after split\n",
        "split_class_counts = {\"train\": Counter(), \"val\": Counter(), \"test\": Counter()}\n",
        "\n",
        "# Split each class equally\n",
        "for class_id, files in class_files.items():\n",
        "    random.shuffle(files)\n",
        "\n",
        "    train_split = int(len(files) * split_ratios[\"train\"])\n",
        "    val_split = int(len(files) * split_ratios[\"val\"])\n",
        "\n",
        "    train_files = files[:train_split]\n",
        "    val_files = files[train_split:train_split + val_split]\n",
        "    test_files = files[train_split + val_split:]\n",
        "\n",
        "    for split, split_files in zip([\"train\", \"val\", \"test\"], [train_files, val_files, test_files]):\n",
        "        sample_count = 0\n",
        "        for file in split_files:\n",
        "            with open(os.path.join(labels_folder, file), \"r\") as f:\n",
        "                sample_count += len(f.readlines())\n",
        "        split_class_counts[split][class_id] = sample_count\n",
        "\n",
        "        for file in split_files:\n",
        "            shutil.copy(os.path.join(labels_folder, file), os.path.join(output_folder, split, \"labels\", file))\n",
        "            image_file = file.replace(\".txt\", \".tif\")\n",
        "            image_path = os.path.join(images_folder, image_file)\n",
        "            shutil.copy(image_path, os.path.join(output_folder, split, \"images\", image_file))\n",
        "\n",
        "class_names = {\n",
        "    0: \"Cow\",\n",
        "    1: \"Haybale_round\",\n",
        "    2: \"Haybale_square\",\n",
        "    3: \"Haystack\",\n",
        "    4: \"Horse\",\n",
        "    5: \"Machinery\",\n",
        "    6: \"Sheep\"\n",
        "}\n",
        "\n",
        "# Create YAML file for training\n",
        "yaml_data = {\n",
        "    \"train\": os.path.abspath(os.path.join(output_folder, \"train\")),\n",
        "    \"val\": os.path.abspath(os.path.join(output_folder, \"val\")),\n",
        "    \"test\": os.path.abspath(os.path.join(output_folder, \"test\")),\n",
        "    \"nc\": len(class_files),\n",
        "    \"names\": [class_names.get(c, str(c)) for c in sorted(class_files.keys())]  # Class names\n",
        "}\n",
        "\n",
        "with open(os.path.join(output_folder, \"dataset.yaml\"), \"w\") as yaml_file:\n",
        "    yaml.dump(yaml_data, yaml_file, default_flow_style=False)"
      ],
      "metadata": {
        "id": "66j55eZ9S1Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Image quality assesment (IQA)**"
      ],
      "metadata": {
        "id": "fv4uzZfCp3Nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1. Importing prerequsisites**"
      ],
      "metadata": {
        "id": "4DLBqeSuEu5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.exposure import match_histograms\n",
        "import skimage\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "UAvrNhFuqRF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2. Random selection of samples**\n"
      ],
      "metadata": {
        "id": "eGIjs2LiE0jC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_path = '/content/GMAI/SAMPLE_DATASET/images' # Path to images\n",
        "labels_path = '/content/GMAI/SAMPLE_DATASET/labels/' # Path to label files\n",
        "\n",
        "txts = glob.glob(f\"{labels_path}/**.txt\", recursive=True)\n",
        "\n",
        "all_classes = [[] for _ in range(7)]\n",
        "samples = []\n",
        "\n",
        "for file in txts:\n",
        "    data = pd.read_csv(file, sep=\" \", header=None)\n",
        "    class_ids = data[0].unique()\n",
        "\n",
        "    for class_num in class_ids:\n",
        "        if 0 <= class_num < 7:\n",
        "            all_classes[int(class_num)].append(file)\n",
        "\n",
        "# Pick random samples for each class\n",
        "for x in all_classes:\n",
        "    sample = random.sample(x,1) # Adjust number of samples for each class\n",
        "    samples.append(sample)\n",
        "\n",
        "img_x = []\n",
        "img_y = []\n",
        "img_name = []\n",
        "\n",
        "# Filter samples at the edges of images\n",
        "for class_num in range(7):\n",
        "    count = 0\n",
        "    for file in samples[class_num]:\n",
        "        data = pd.read_csv(file, sep=\" \", header=None)\n",
        "        data = data[data[0] == class_num]\n",
        "        data = data.sample(n=1)\n",
        "        y = int(data[1].iloc[0] * 1280 - 30)\n",
        "        x = int(data[2].iloc[0] * 1280 - 30)\n",
        "        if y > 60 and y < 1220:\n",
        "            if x > 60 and x < 1220:\n",
        "                img_y.append(y)\n",
        "                img_x.append(x)\n",
        "                img_name.append(os.path.join(images_path, os.path.basename(os.path.splitext(file)[0]+'.tif')))"
      ],
      "metadata": {
        "id": "wLYyk62SqAI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3. Resizing and IQA metrics calculation**\n"
      ],
      "metadata": {
        "id": "GE5EaQTnEsEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def IQA(image,x,y):\n",
        "    image = Image.open(image)\n",
        "    image = image.convert(\"RGB\")\n",
        "    image = np.array(image)\n",
        "\n",
        "    crop_size = 60\n",
        "\n",
        "    cropped = tf.image.crop_to_bounding_box(image, x, y, crop_size, crop_size) # Crops image around sample\n",
        "    resized_20 = tf.image.resize(cropped, [int(crop_size * 0.75), int(crop_size * 0.75)], method = 'area')/255 # Resize image to correspond GSD of 20cm\n",
        "    resized_25 = tf.image.resize(cropped, [int(crop_size * 0.6), int(crop_size * 0.6)], method = 'area')/255 # Resize image to correspond GSD of 25cm\n",
        "\n",
        "    methods = ['nearest','bicubic','lanczos3','lanczos5','gaussian'] # Tested interpolation methods\n",
        "\n",
        "    metrics = []\n",
        "\n",
        "    for method in methods:\n",
        "        globals()[f'resized_20_{method}'] = tf.image.resize(resized_20, [int(crop_size), int(crop_size)], method = method)\n",
        "        globals()[f'resized_25_{method}'] = tf.image.resize(resized_25, [int(crop_size), int(crop_size)], method = method)\n",
        "\n",
        "        img=globals()[f'resized_20_{method}'].numpy()\n",
        "        ref=tf.image.convert_image_dtype(cropped, dtype=tf.float32).numpy()\n",
        "\n",
        "        # Resize images from 20cm back to 15cm and compute IQA metrics\n",
        "        matched_20 = match_histograms(img, ref, channel_axis= -1)\n",
        "\n",
        "        SSIM_20 = tf.image.ssim(cropped/255, globals()[f'resized_20_{method}'], max_val=1.0,filter_size=9,\n",
        "                              filter_sigma=1, k1=0.01, k2=0.03)\n",
        "        SSIM_20_matched = tf.image.ssim(cropped/255, matched_20, max_val=1.0,filter_size=9,\n",
        "                              filter_sigma=1, k1=0.01, k2=0.03)\n",
        "        PSNR_20 = tf.image.psnr(cropped/255, globals()[f'resized_20_{method}'], max_val = 1.0)\n",
        "        PSNR_20_matched = tf.image.psnr(cropped/255, matched_20, max_val = 1.0)\n",
        "        MSE_20 = skimage.metrics.mean_squared_error(ref,img)\n",
        "        MSE_20_matched = skimage.metrics.mean_squared_error(ref,matched_20)\n",
        "        MAE_20 = tf.reduce_mean(tf.abs(cropped/255-globals()[f'resized_20_{method}']))\n",
        "        MAE_20_matched = tf.reduce_mean(tf.abs(cropped/255-matched_20))\n",
        "\n",
        "        # Resize images from 25cm back to 15cm and compute IQA metrics\n",
        "        img=globals()[f'resized_25_{method}'].numpy()\n",
        "        matched_25 = match_histograms(img, ref, channel_axis= -1)\n",
        "\n",
        "        SSIM_25 = tf.image.ssim(cropped/255, globals()[f'resized_25_{method}'], max_val=1.0,filter_size=9,\n",
        "                              filter_sigma=1, k1=0.01, k2=0.03)\n",
        "        SSIM_25_matched = tf.image.ssim(cropped/255, matched_25, max_val=1.0,filter_size=9,\n",
        "                              filter_sigma=1, k1=0.01, k2=0.03)\n",
        "        PSNR_25 = tf.image.psnr(cropped/255, globals()[f'resized_25_{method}'], max_val = 1.0)\n",
        "        PSNR_25_matched = tf.image.psnr(cropped/255, matched_25, max_val = 1.0)\n",
        "        MSE_25 = skimage.metrics.mean_squared_error(ref,img)\n",
        "        MSE_25_matched = skimage.metrics.mean_squared_error(ref,matched_25)\n",
        "        MAE_25 = tf.reduce_mean(tf.abs(cropped/255-globals()[f'resized_25_{method}']))\n",
        "        MAE_25_matched = tf.reduce_mean(tf.abs(cropped/255-matched_25))\n",
        "\n",
        "        globals()[f'stat_{method}_20'] = [float(SSIM_20),float(PSNR_20),float(MSE_20),float(MAE_20)]\n",
        "        globals()[f'stat_{method}_20_matched'] = [float(SSIM_20_matched),float(PSNR_20_matched),float(MSE_20_matched),float(MAE_20_matched)]\n",
        "        globals()[f'stat_{method}_25'] = [float(SSIM_25),float(PSNR_25),float(MSE_25),float(MAE_25)]\n",
        "        globals()[f'stat_{method}_25_matched'] = [float(SSIM_25_matched),float(PSNR_25_matched),float(MSE_25_matched),float(MAE_25_matched)]\n",
        "\n",
        "        metrics.append(globals()[f'stat_{method}_20'])\n",
        "        metrics.append(globals()[f'stat_{method}_20_matched'])\n",
        "        metrics.append(globals()[f'stat_{method}_25'])\n",
        "        metrics.append(globals()[f'stat_{method}_25_matched'])\n",
        "\n",
        "        return metrics\n",
        "\n",
        "all_metrics = []\n",
        "for i in range(len(img_name)):\n",
        "    metrics = IQA(img_name[i], img_x[i], img_y[i])\n",
        "    all_metrics.extend(metrics)\n",
        "\n",
        "methods = ['nearest', 'bicubic', 'lanczos3', 'lanczos5', 'gaussian']\n",
        "matched = ['no', 'yes']\n",
        "\n",
        "data = []\n",
        "\n",
        "for i, m in enumerate(all_metrics):\n",
        "    method_idx = (i // 4) % 5\n",
        "    matched_flag = matched[i % 2]\n",
        "    data.append({\n",
        "        'method': methods[method_idx],\n",
        "        'matched': matched_flag,\n",
        "        'SSIM': m[0],\n",
        "        'PSNR': m[1],\n",
        "        'MSE': m[2],\n",
        "        'MAE': m[3]\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df_long = df.melt(id_vars=['method', 'matched'],\n",
        "                  var_name='metric', value_name='value')\n",
        "\n",
        "summary = (\n",
        "    df_long\n",
        "    .groupby(['metric', 'method', 'matched'])['value']\n",
        "    .agg(['mean', 'std'])\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "summary['mean'] = summary['mean'].round(4)\n",
        "summary['std'] = summary['std'].round(4)\n",
        "\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "CPD50BkOsu82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. YOLO11 training**"
      ],
      "metadata": {
        "id": "24FGzD1t7hTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1. Importing prerequsisites**"
      ],
      "metadata": {
        "id": "trtMRnU1FvEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import os"
      ],
      "metadata": {
        "id": "QPttrJk57oJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2. Checks CUDA availability**"
      ],
      "metadata": {
        "id": "hBNQG4yFF3Q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Is CUDA supported? {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name()}\")"
      ],
      "metadata": {
        "id": "mVj4VqzQ95Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3. Training setup**"
      ],
      "metadata": {
        "id": "k2EN7aSwGWhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_sizes = [\"n\", \"s\", \"m\", \"l\", \"x\"] #Model variants\n",
        "optimizers = [\"AdamW\",\"SGD\"] #Optimizers\n",
        "pretrained_options = [True,False] #Determing if model is pretrained or not\n",
        "batch_sizes = [8, 16, 32] #Batch sizes\n",
        "data_path = \"/content/GMAI/SAMPLE_DATASET/final_dataset/dataset.yaml\" #Path to YAML file of dataset\n",
        "project_name = \"training\"\n",
        "epochs = 100 #Epoch number\n",
        "img_size = 1280\n",
        "if torch.cuda.is_available(): #If CUDA is available, chooses GPU for training\n",
        "  device = [0]\n",
        "else:\n",
        "  device = 'cpu'"
      ],
      "metadata": {
        "id": "zPLo4dmx-Orf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.4. Training loop**"
      ],
      "metadata": {
        "id": "B-4F2QcFGg04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for size in model_sizes:\n",
        "    for optimizer in optimizers:\n",
        "        for pretrained in pretrained_options:\n",
        "            for batch_size in batch_sizes:\n",
        "                run_name = f\"YOLO11_{size}_{optimizer}_bs{batch_size}_{'pretrained' if pretrained else 'scratch'}\"\n",
        "                print(f\"\\nTraining YOLOv11{size} | {optimizer} | Pretrained: {pretrained} | Batch: {batch_size} ...\")\n",
        "\n",
        "                if pretrained:\n",
        "                    model = YOLO(f\"yolo11{size}.pt\")\n",
        "                else:\n",
        "                    model = YOLO(f\"yolo11{size}.pt\")\n",
        "                    model.model.reset_parameters()  # Removes pretrained weights\n",
        "\n",
        "                results = model.train(\n",
        "                    data=data_path,\n",
        "                    epochs=epochs,\n",
        "                    imgsz=img_size,\n",
        "                    batch=batch_size,\n",
        "                    device=device,\n",
        "                    project=project_name,\n",
        "                    name=run_name,\n",
        "                    optimizer=optimizer,\n",
        "                    augment=False,\n",
        "                    val=True,\n",
        "                    verbose=True\n",
        "                )\n",
        "\n",
        "                torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dEa_l6hO-cXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Inference with trained model**"
      ],
      "metadata": {
        "id": "3Xl0-l7wBaOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1. Importing prerequsisites**"
      ],
      "metadata": {
        "id": "g6KHi_CVH4DF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import os\n",
        "from pathlib import Path\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Polygon\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rasterio.crs import CRS\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "tGYL1I0YI4J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2. Checks CUDA availability**"
      ],
      "metadata": {
        "id": "qKj3KaRKH5az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Is CUDA supported? {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
        "\n",
        "if torch.cuda.is_available(): #If CUDA is available, chooses GPU for predictions\n",
        "  device = [0]\n",
        "else:\n",
        "  device = 'cpu'"
      ],
      "metadata": {
        "id": "2rZKnEdN9Jqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2. Find images for predictions**\n",
        "\n"
      ],
      "metadata": {
        "id": "ZuhM4v_GIAh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = r\"/content/GMAI/SAMPLE_ORTO\"\n",
        "out_path = r\"/content/GMAI/predictions\"\n",
        "\n",
        "os.makedirs(out_path,exist_ok=True)\n",
        "\n",
        "all_polygons, all_classes, all_confidences = [], [], []\n",
        "\n",
        "tif_files = []\n",
        "\n",
        "for dirpath, _, filenames in os.walk(img_path):\n",
        "    for file in filenames:\n",
        "        if file.lower().endswith(('.tif', '.tiff')):\n",
        "            full_path = os.path.join(dirpath, file)\n",
        "            tif_files.append(full_path)\n",
        "\n",
        "print(\"Images found:\",len(tif_files))"
      ],
      "metadata": {
        "id": "JlgAf78TBen5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.3. Inference loop**"
      ],
      "metadata": {
        "id": "YrvWr_AcIHpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image in tif_files:\n",
        "\n",
        "    image_folder = os.path.join(out_path, os.path.basename(os.path.splitext(image)[0]))\n",
        "    os.makedirs(image_folder,exist_ok=True)\n",
        "\n",
        "    tile_folder = os.path.join(image_folder, \"tile\")\n",
        "    os.makedirs(tile_folder,exist_ok=True)\n",
        "\n",
        "    #Tile\n",
        "    with rasterio.open(image,\"r+\") as src:\n",
        "        crs = src.crs\n",
        "        image_width = src.width\n",
        "        image_height = src.height\n",
        "        tiling_size = 1280\n",
        "        overlap = 0.1\n",
        "        stride_x, stride_y = int(tiling_size * (1 - overlap)), int(tiling_size * (1 - overlap))\n",
        "\n",
        "        tile_id=0\n",
        "\n",
        "        for top in range(0, image_height, stride_y):\n",
        "            for left in range(0, image_width, stride_x):\n",
        "                if left + tiling_size > image_width:\n",
        "                    left = image_width - tiling_size\n",
        "                if top + tiling_size > image_height:\n",
        "                    top = image_height - tiling_size\n",
        "                window = Window(left, top, tiling_size, tiling_size)\n",
        "                bounds = rasterio.windows.bounds(window, transform=src.transform)\n",
        "                minX, minY, maxX, maxY = bounds\n",
        "                tile_path = os.path.join(tile_folder, f\"{os.path.basename(os.path.splitext(image)[0])}_{tile_id}.tif\")\n",
        "                tile_id+=1\n",
        "                tile_data = src.read(indexes=[1, 2, 3],window=window)\n",
        "                with rasterio.open(\n",
        "                                tile_path,\n",
        "                                \"w\",\n",
        "                                driver=\"GTiff\",\n",
        "                                height=tile_data.shape[1],\n",
        "                                width=tile_data.shape[2],\n",
        "                                count=3,\n",
        "                                dtype=tile_data.dtype,\n",
        "                                crs=crs,\n",
        "                                transform=src.window_transform(window),\n",
        "                            ) as dst:\n",
        "                                dst.write(tile_data)\n",
        "\n",
        "    if tiling_size != 1280:\n",
        "      for image in os.listdir(image_folder):\n",
        "          image_path = os.path.join(image_folder,image)\n",
        "          image = Image.open(image)\n",
        "          image = image.convert(\"RGB\")\n",
        "          image = np.array(image)\n",
        "          image = tf.image.resize(image, [1280, 1280], method = 'lanczos5')\n",
        "          image = tf.cast(image, tf.uint8).numpy()\n",
        "          tiff.imwrite(image_path, image)\n",
        "\n",
        "\n",
        "    model = YOLO(\"/content/GMAI/YOLO11x_GMAI.pt\")\n",
        "\n",
        "    results = model.predict(\n",
        "        source=tile_folder,\n",
        "        conf=0.3,\n",
        "        imgsz=1280,\n",
        "        save_txt=True,\n",
        "        save_conf=True,\n",
        "        project = image_folder,\n",
        "        name='predict')\n",
        "\n",
        "    for result in results:\n",
        "            image_path = Path(result.path)\n",
        "            image_name = image_path.stem\n",
        "            boxes = result.boxes\n",
        "\n",
        "            if boxes is not None and len(boxes) > 0:\n",
        "                result_path = os.path.join(image_folder, f\"{image_name}.tif\")\n",
        "                result.save(filename=result_path)\n",
        "\n",
        "                txt_filename = f\"{image_name}.txt\"\n",
        "                txt_source_path = os.path.join(image_folder,\"predict/labels\", txt_filename)  # Default YOLO output folder\n",
        "                txt_dest_path = os.path.join(image_folder,'labels', txt_filename)\n",
        "                os.makedirs(os.path.dirname(txt_dest_path), exist_ok=True)\n",
        "                if os.path.exists(txt_source_path):\n",
        "                    shutil.move(txt_source_path, txt_dest_path)\n",
        "\n",
        "\n",
        "shutil.rmtree(os.path.join(image_folder,\"predict\"))"
      ],
      "metadata": {
        "id": "rad7f1u6HJTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.4. Shapefile creation**"
      ],
      "metadata": {
        "id": "y54t0cJdIZUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf = {}\n",
        "if os.path.isdir(os.path.join(image_folder,'labels')):\n",
        "  for file in os.listdir(os.path.join(image_folder,'labels')):\n",
        "    df = pd.read_csv(os.path.join(image_folder,'labels',file), delimiter=' ', header=None, names=[\"class_id\", \"cx\", \"cy\", \"w\", \"h\", \"conf\"])\n",
        "    tile_path = os.path.join(tile_folder,f\"{os.path.basename(os.path.splitext(file)[0])}.tif\")\n",
        "\n",
        "    with rasterio.open(tile_path) as src:\n",
        "      transform = src.transform\n",
        "      crs = src.crs\n",
        "      img_w, img_h = src.width, src.height\n",
        "      df[[\"cx\", \"w\"]] *= img_w\n",
        "      df[[\"cy\", \"h\"]] *= img_h\n",
        "      x_min, x_max = df[\"cx\"] - df[\"w\"] / 2, df[\"cx\"] + df[\"w\"] / 2\n",
        "      y_min, y_max = df[\"cy\"] - df[\"h\"] / 2, df[\"cy\"] + df[\"h\"] / 2\n",
        "      bbox_coords = np.column_stack([x_min, y_min, x_min, y_max, x_max, y_max, x_max, y_min, x_min, y_min])\n",
        "      bbox_coords = bbox_coords.reshape(-1, 5, 2)\n",
        "      transformed_coords = np.apply_along_axis(lambda pt: transform * tuple(pt), 2, bbox_coords)\n",
        "\n",
        "      polygons = [Polygon(coords) for coords in transformed_coords]\n",
        "\n",
        "      all_polygons.extend(polygons)\n",
        "      all_classes.extend(df[\"class_id\"].astype(int))\n",
        "      all_confidences.extend(df[\"conf\"])\n",
        "\n",
        "gdf = gpd.GeoDataFrame(\n",
        "  {\"geometry\": all_polygons, \"class_id\": all_classes, \"confidence\": all_confidences},\n",
        "   crs=crs\n",
        "    )\n",
        "\n",
        "gdf.to_file(os.path.join(out_path, \"predictions.shp\"), driver=\"ESRI Shapefile\")"
      ],
      "metadata": {
        "id": "hwpBBumhhDOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.5. Download results**"
      ],
      "metadata": {
        "id": "mpLTNXLzIsnA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b307a76"
      },
      "source": [
        "zip_filename = \"predictions.zip\"\n",
        "shutil.make_archive(zip_filename.replace(\".zip\", \"\"), 'zip', out_path)\n",
        "files.download(zip_filename)\n",
        "\n",
        "print(f\"Folder '{out_path}' compressed to '{zip_filename}' and downloaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}